---
layout: detail
title: "GeoRTNet : Geometric Perception based Efficient Text Recognition"
description: "Efficiency Meets Accuracy: Pioneering Specialized Models for Scene Text Recognition"
image: assets/images/publications/geortnet_pic1.png
categories: publications
type: publication
permalink: /:categories/:title
tag: In review
---

<div id="main">
    <!-- One -->
    <section id="one">
        <div class="inner no-padding" >
            <div class="table-container">
            <table>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">Title</a></td>
                    <td class="second-column"><a href="#" class="button small disable">GeoRTNet: Geometric Perception based Efficient Text Recognition</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">Date</a></td>
                    <td class="second-column"><a href="#" class="button small disable">August 2022</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">Venue</a></td>
                    <td class="second-column"><a href="#" class="button small disable">Future of Information and Communication Conference (FICC)</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small disable">Status</a></td>
                    <td class="second-column"><a href="#" class="button small disable">In Review</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">Authors</a></td>
                    <td class="second-column"><a href="#" class="button small disable">P.N.Deelaka, D.R.Jayakody, D.Y.Silava</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">keyword</a></td>
                    <td class="second-column"><a href="#" class="button small disable"> Scene Text Recognition, federated learning, metric learning</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="https://github.com/ACRA-FL/GeoTRNet" class="button special small"><i class="fab fa-github"></i>Code</a></td>
                    <td class="second-column"><a href="https://arxiv.org/abs/2302.03873" class="button special small"><i class="fa-solid fa-file-pdf"></i>Paper</a></td>
                </tr> 
            </table>
            </div>
        </div>
    </section>
    <!-- Second -->
    <section id='second'>
        <div class="inner no-padding">
            <div>
                <h2>Abstract</h2>
                    <img src="{% link assets/images/publications/geortnet_pic1.png %}" width="100%" />
                    <p>Every Scene Text Recognition (STR) task consists of text localization \& text recognition as the prominent sub-tasks. However, in real-world applications with fixed camera positions such as equipment monitor reading, image-based data entry, and printed document data extraction, the underlying data tends to be regular scene text. Hence, in these tasks, the use of generic, bulky models comes up with significant disadvantages compared to customized, efficient models in terms of model deployability, data privacy \& model reliability. Therefore, this paper introduces the underlying concepts, theory, implementation, and experiment results to develop models, which are highly specialized for the task itself, to achieve not only the SOTA performance but also to have minimal model weights, shorter inference time, and high model reliability. We introduce a novel deep learning architecture (GeoTRNet), trained to identify digits in a regular scene image, only using the geometrical features present, mimicking human perception over text recognition</p>
                    <h3>Key Contributions</h3>
                    <ul class='fa-ul'>
                        <li><i class="fa-li fa fa-check-square"></i>Novel Image Feature Encoding</li>
                        <li><i class="fa-li fa fa-check-square"></i>Spatial Attention Mechanism</li>
                        <li><i class="fa-li fa fa-check-square"></i>Fully-Convolutional multi-class multi-Label Prediction</li>
                        <li><i class="fa-li fa fa-check-square"></i>Synthetic Data Generation</li>
                    </ul>
            </div>
            <div>
                <h2>Lessons Learned</h2>
                <ul class='fa-ul'>
                    <li><i class="fa-li fa fa-check-square"></i>Geometry-Centric Approach</li>
                    <li><i class="fa-li fa fa-check-square"></i>Innovative Label Prediction</li>
                    <li><i class="fa-li fa fa-check-square"></i>Data Diversity</li>
                    <li><i class="fa-li fa fa-check-square"></i>Empirical Validation</li>
                </ul>
            </div>
        </div>
    </section>
</div>