---
layout: detail
title: "TEZARNet: TEmporal Zero-shot Activity Recognition Network"
description: "Unlocking the Future of Human Activity Recognition: TEZARNet's Breakthrough in Zero-shot HAR from IMU Sensor Data and Videos"
image: assets/images/publications/terzanet_pic1.jpg
categories: publications
type: publication
permalink: /:categories/:title
tag: accepted
---

<div id="main">
    <!-- One -->
    <section id="one">
        <div class="inner no-padding" >
            <div class="table-container">
            <table>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">Title</a></td>
                    <td class="second-column"><a href="#" class="button small disable">TEZARNet: TEmporal Zero-shot Activity Recognition Network</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">Date</a></td>
                    <td class="second-column"><a href="#" class="button small disable">August 2023</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">Venue</a></td>
                    <td class="second-column"><a href="#" class="button small disable">ICONIP, Grade-B Conference</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small disable">Status</a></td>
                    <td class="second-column"><a href="#" class="button small disable">Accepted</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">Authors</a></td>
                    <td class="second-column"><a href="#" class="button small disable">Pathirage N. Deelaka, Devin Y. Silva, Sandareka Wickramanayake, Dulani Meedeniya, Sanka Rasnayaka</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">keyword</a></td>
                    <td class="second-column"><a href="#" class="button small disable"> Human Activity Recognition, Zero-shot Learning, Inertial Measurement Unit Data.</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="https://github.com/nipdep/TEZARNet" class="button special small"><i class="fab fa-github"></i>Code</a></td>
                    <td class="second-column"><a href="#" class="button special small disable"><i class="fa-solid fa-file-pdf"></i>Paper</a></td>
                </tr> 
            </table>
            </div>
        </div>
    </section>
    <!-- Second -->
    <section id='second'>
        <div class="inner no-padding">
            <div>
                <h2>Abstract</h2>
                    <img src="{% link assets/images/publications/terzanet_pic1.jpg %}" width="100%" />
                    <p>Human Activity Recognition (HAR) using Inertial Measurement Unit (IMU) sensor data has practical applications in healthcare and assisted living environments. However, its use in real-world scenarios has been limited due to the lack of comprehensive IMU-based HAR datasets covering various activities. Zero-shot HAR (ZS-HAR) can overcome these data limitations. However, most existing ZS-HAR methods based on IMU data rely on attributes or word embeddings of class labels as auxiliary data to relate the seen and unseen classes. This approach requires expert knowledge and lacks motion-specific information. In contrast, videos depicting various human activities provide valuable information for ZS-HAR based on inertial sensor data, and they are readily available. Our proposed model, TEZARNet: TEmporal Zero-shot Activity Recognition Network, uses videos as auxiliary data and employs a Bidirectional Long-Short Term IMU encoder to exploit temporal information, distinguishing it from current work. The proposed model outperforms the state-of-the-art accuracy by 4.7\%, 7.8\%, 3.7\%, and 9.3\% for benchmark datasets PAMAP2, DaLiAc, UTD-MHAD, and MHEALTH, respectively</p>
                    <h3>Key Contributions</h3>
                    <ul class='fa-ul'>
                        <li><i class="fa-li fa fa-check-square"></i>Utilization of Temporal Information IMU based HAR</li>
                        <li><i class="fa-li fa fa-check-square"></i>Semantic Space Construction</li>
                        <li><i class="fa-li fa fa-check-square"></i>K-Nearest Neighbour (KNN) Inference</li>
                        <li><i class="fa-li fa fa-check-square"></i>Significant Performance Improvements</li>
                    </ul>
            </div>
            <div>
                <h2>Lessons Learned</h2>
                <ul class='fa-ul'>
                    <li><i class="fa-li fa fa-check-square"></i>Temporal Information Matters</li>
                    <li><i class="fa-li fa fa-check-square"></i>Utilizing Videos for Semantic Space</li>
                    <li><i class="fa-li fa fa-check-square"></i>Account for Model Reproducibility specially in ZSL training</li>
                </ul>
            </div>
        </div>
    </section>
</div>