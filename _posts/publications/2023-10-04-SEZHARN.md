---
layout: detail
title: "SEZ-HARN: Self-Explainable Zero-shot Human Activity Recognition Network"
description: "Unveiling Human Activities: SEZ-HARN - Bridging the Gap in Transparent Zero-Shot HAR"
image: assets/images/publications/sezharn_pic1.png
categories: publications
type: publication
permalink: /:categories/:title
tag: In review
---

<div id="main">
    <!-- One -->
    <section id="one">
        <div class="inner no-padding" >
            <div class="table-container">
            <table>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">Title</a></td>
                    <td class="second-column"><a href="#" class="button small disable">SEZ-HARN: Self-Explainable Zero-shot Human Activity Recognition Network</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">Date</a></td>
                    <td class="second-column"><a href="#" class="button small disable">September 2023</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">Venue</a></td>
                    <td class="second-column"><a href="#" class="button small disable">AAAI, Grade-A conference</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small disable">Status</a></td>
                    <td class="second-column"><a href="#" class="button small disable">In Review</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">Authors</a></td>
                    <td class="second-column"><a href="#" class="button small disable">Pathirage N. Deelaka, Devin Y. Silva, Sandareka Wickramanayake, Dulani Meedeniya, Sanka Rasnayaka</a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="#" class="button special small">keyword</a></td>
                    <td class="second-column"><a href="#" class="button small disable"> Human Activity Recognition, Zero-Shot Learning, Explainability </a></td>
                </tr>
                <tr>
                    <td class="first-column"><a href="https://github.com/nipdep/SEZ-HARN" class="button special small"><i class="fab fa-github"></i>Code</a></td>
                    <td class="second-column"><a href="#" class="button special small disable"><i class="fa-solid fa-file-pdf"></i>Paper</a></td>
                </tr> 
            </table>
            </div>
        </div>
    </section>
    <!-- Second -->
    <section id='second'>
        <div class="inner no-padding">
            <div>
                <h2>Abstract</h2>
                    <img src="{% link assets/images/publications/sezharn_pic1.png %}" width="100%" />
                    <p>Human Activity Recognition (HAR) using data from Inertial Measurement Unit (IMU) sensors has many practical applications in healthcare and assisted living environments. However, its use in real-world scenarios has been limited by the lack of comprehensive IMU-based HAR datasets that cover a wide range of activities and the lack of transparency in existing models. Zero-shot HAR (ZS-HAR) overcomes the data limitations, but current models struggle to explain their decisions, making them less transparent. This paper introduces a novel IMU-based ZS-HAR model called the Self-Explainable Zero-shot Human Activity Recognition Network (SEZ-HARN). It can recognize activities not encountered during training and provide skeleton videos to explain its decision-making process. Experiment results on four benchmark datasets (PAMAP2, DaLiAc, UTD-MHAD, and MHEALTH) show that SEZ-HARN produces realistic and understandable explanations while outperforming other black ZS-HAR models in Zero-shot prediction accuracy.</p>
                    <h3>Key Contributions</h3>
                    <ul class='fa-ul'>
                        <li><i class="fa-li fa fa-check-square"></i>Utilization of Video Data for Semantic Spaces</li>
                        <li><i class="fa-li fa fa-check-square"></i>Bidirectional Long-Short Term Memory (Bi-LSTM) IMU Encoder</li>
                        <li><i class="fa-li fa fa-check-square"></i>Human-Understandable Explanations</li>
                    </ul>
            </div>
            <div>
                <h2>Lessons Learned</h2>
                <ul class='fa-ul'>
                    <li><i class="fa-li fa fa-check-square"></i>Human-Understandable Explanations</li>
                    <li><i class="fa-li fa fa-check-square"></i>Effective IMU Signal Processing</li>
                    <li><i class="fa-li fa fa-check-square"></i>Model Transparency</li>
                </ul>
            </div>
        </div>
    </section>
</div>